---
name: cassandra

packages:
  - cassandra
  - openjdk
  - python

provides:
  - name: cassandra
    type: cassandra
    properties:
      - cassandra_password
      - native_transport_port
      - client_encryption.enabled
      - client_encryption.require_client_auth
      - cert
      - cluster_name
      - system_auth_keyspace_replication_factor     

consumes:
  - name: seeds
    type: cassandra
  - name: non_seeds
    type: cassandra

templates:
  bin/pre-start.sh: bin/pre-start
  bin/generate-keystores.sh: bin/generate-keystores.sh
  bpm.yml: config/bpm.yml
  bpm-prestart: bpm-prestart
  bin/drain: bin/drain
  bin/cassandra_ctl: bin/cassandra_ctl
  bin/monit_debugger: bin/monit_debugger
  data/properties.sh.erb: data/properties.sh
  helpers/ctl_setup.sh: helpers/ctl_setup.sh
  helpers/ctl_utils.sh: helpers/ctl_utils.sh
  config/cassandra-jaas.config.erb: conf/cassandra-jaas.config
  config/jvm.options.erb: conf/jvm.options
  config/cassandra.yaml.erb: conf/cassandra.yaml
  config/cassandra-env.sh.erb: conf/cassandra-env.sh
  config/cassandra-rackdc.properties.erb: conf/cassandra-rackdc.properties
  config/cassandra-topology.properties.erb: conf/cassandra-topology.properties
  config/logback.xml.erb: conf/logback.xml
  config/logback-tools.xml.erb: conf/logback-tools.xml
  config/commitlog_archiving.properties.erb: conf/commitlog_archiving.properties
  ssl2/cert: tls/node.crt
  ssl2/cert_ca: tls/ca.crt
  ssl2/cert_private_key: tls/node.key
  config/cqlshrc.erb: root/.cassandra/cqlshrc
  bin/post-deploy.sh: bin/post-deploy
  config/jmx_exporter.yml: conf/jmx_exporter.yml
  bin/nodetool: bin/nodetool
  bin/sstableloader: bin/sstableloader
  bin/cqlsh: bin/cqlsh

properties:
  bpm.enabled:
    description: |
      Switch to BPM (Bosh Process Manager) for running Cassandra. This brings
      the benefit of improved security measures at runtime.
    default: false
  cluster_name:
    description: |
      The name of the cluster. This is mainly used to prevent machines in one
      logical cluster from joining another.
    default: testcluster # 'Test Cluster'
  num_tokens:
    description: |
      Defines the number of tokens randomly assigned to each node of the
      instance group. The more tokens, relative to nodes of other instance
      groups, the larger the proportion of data that this node will store.

      When defining different instance groups for a single Cassandra cluster,
      each with varying hardware capabilities, then the number of tokens
      assigned to nodes of must be relative to their hardware capabilities.
    default: 256
  hinted_handoff_enabled:
    description: |
      Enables or disables hinted handoff. To enable per datacenter, add a list
      of datacenters. For example: 'hinted_handoff_enabled: DC1,DC2'. A hint
      indicates that the write needs to be replayed to an unavailable node.
      Cassandra writes the hint to a hints file on the coordinator node.

      See: <http://wiki.apache.org/cassandra/HintedHandoff>
      See: <https://www.datastax.com/dev/blog/modern-hinted-handoff>
    default: true
    example: DC1,DC2
  max_hint_window_in_ms:
    description: |
      Maximum amount of time (in milliseconds) during which Cassandra
      generates hints for an unresponsive node. After this interval, Cassandra
      does not generate any new hints for the node until it is back up and
      responsive. If the node goes down again, Cassandra starts a new
      interval.
    default: 10800000 # 3 hours
  hinted_handoff_throttle_in_kb:
    description: |
      Maximum amount of traffic per delivery thread in kilobytes per second.
      This rate reduces proportionally to the number of nodes in the cluster.
      For example, if there are two nodes in the cluster, each delivery thread
      uses the maximum rate. If there are three, each node throttles to half
      of the maximum, since the two nodes are expected to deliver hints
      simultaneously.
    default: 1024
  max_hints_delivery_threads:
    description: |
      Number of threads Cassandra uses to deliver hints. In multiple data-
      center deployments, consider increasing this number because cross data-
      center handoff is generally slower.
    default: 2
  authenticator:
    description: |
      The authentication backend. It implements IAuthenticator for identifying
      users. Available authenticators:

      - AllowAllAuthenticator:
        Disables authentication; Cassandra performs no checks.

      - PasswordAuthenticator:
        Authenticates users with user names and hashed passwords stored in the
        'system_auth.roles' table. Leaving the default replication factor of 1
        set for the 'system_auth' keyspace results in denial of access to the
        cluster if the single replica of the keyspace goes down.
    default: PasswordAuthenticator
  authorizer:
    description: |
      The authorization backend. It implements IAuthenticator to limit access
      and provide permissions. Available authorizers:

      - AllowAllAuthorizer:
        Disables authorization: Cassandra allows any action to any user.

      - CassandraAuthorizer:
        Stores permissions in 'system_auth.permissions' table. Setting
        'system_auth_keyspace_replication_factor' to 1 results in denial of
        access to the cluster if the single replica of the keyspace goes down.
    default: CassandraAuthorizer
  roles_validity_in_ms:
    description: |
      Fetching permissions can be an expensive operation depending on the
      authorizer, so this setting allows flexibility. Validity period for
      roles cache; set to '0' to disable. Granted roles are cached for
      authenticated sessions in 'AuthenticatedUser' and after the period
      specified here, become eligible for (async) reload. Disabled
      automatically for 'AllowAllAuthenticator'.
    default: 2000
  permissions_validity_in_ms:
    description: |
      How many milliseconds permissions in cache remain valid. Depending on
      the authorizer, such as 'CassandraAuthorizer', fetching permissions can
      be resource intensive. This setting is disabled when set to 0 or when
      'authorizer' is set to 'AllowAllAuthorizer'.
    default: 2000
  credentials_validity_in_ms:
    description: |
      How many milliseconds credentials in the cache remain valid. This cache
      is tightly coupled to the provided 'PasswordAuthenticator'
      implementation of 'IAuthenticator'. If another 'IAuthenticator'
      implementation is configured, Cassandra does not use this cache, and
      these settings have no effect. Set to '0' to disable.

        Note: Credentials are cached in encrypted form. This may cause a
        performance penalty that offsets the reduction in latency gained by
        caching.
    default: 2000
  partitioner:
    description: |
      Sets the class that distributes rows (by partition key) across all nodes
      in the cluster. Any IPartitioner may be used, including your own as long
      as it is in the class path. For new clusters use the default
      partitioner.

      Cassandra provides the following partitioners for backwards
      compatibility:
      - RandomPartitioner
      - ByteOrderedPartitioner (deprecated)
      - OrderPreservingPartitioner (deprecated)
    default: org.apache.cassandra.dht.Murmur3Partitioner
  disk_failure_policy:
    description: |
      Sets how Cassandra responds to disk failure. Recommend settings: 'stop'
      or 'best_effort'. Valid values:

      - die:
        Shut down gossip and Thrift and kill the JVM for any file system
        errors or single SSTable errors, so the node can be replaced.

      - stop_paranoid:
        Shut down gossip and Thrift even for single SSTable errors.

      - stop:
        Shut down gossip and Thrift, leaving the node effectively dead, but
        available for inspection using JMX.

      - best_effort:
        Stop using the failed disk and respond to requests based on the
        remaining available SSTables. This allows obsolete data at consistency
        level of ONE.

      - ignore:
        Ignore fatal errors and lets the requests fail; all file system errors
        are logged but otherwise ignored. Cassandra acts as in versions prior
        to 1.2.
    default: stop
  key_cache_size_in_mb:
    description: |
      A global cache setting for the maximum size of the key cache in memory
      (for all tables). To disable set to '0'.

      If an empty string or a 'null' value is set, the cache is set to the
      smaller of 5% of the available heap (when heap size is below 2GB), or
      100MB.
    default: null # min(5% of heap, 100MB)
    example: 100
  key_cache_save_period:
    description: |
      Duration in seconds that keys are kept in cache. Saved caches greatly
      improve cold-start speeds and have relatively little effect on I/O.
    default: 14400 # 4 hours
  row_cache_size_in_mb:
    description: |
      Maximum size of the row cache in memory. The row cache can save more
      time than 'key_cache_size_in_mb', but it is space-intensive because it
      contains the entire row. Use the row cache only for hot rows or static
      rows. If you reduce the size, you may not get you hottest keys loaded on
      start up.
    default: 0
  row_cache_save_period:
    description: |
      The number of seconds that rows are kept in cache. This setting has
      limited use as described in 'row_cache_size_in_mb'.
    default: 0
  commitlog_sync:
    description: |
      The method that Cassandra uses to acknowledge writes in milliseconds:

      - periodic: (Default: 10000 milliseconds [10 seconds])
        With 'commitlog_sync_period_in_ms', controls how often the commit log
        is synchronized to disk. Periodic syncs are acknowledged immediately.

      - batch: (Default: disabled)
        Used with 'commitlog_sync_batch_window_in_ms' (Default: 2 ms), which
        is the maximum length of time that queries may be batched together.
    default: periodic
  commitlog_sync_period_in_ms:
    description: |
      When 'commitlog_sync' is set to 'periodic', this controls how often the
      commit log is synchronized to disk. Periodic syncs are acknowledged
      immediately.
    default: 10000
  commitlog_segment_size_in_mb:
    description: |
      The size of an individual commitlog file segment. A commitlog segment
      may be archived, deleted, or recycled after all its data has been
      flushed to SSTables. This data can potentially include commitlog
      segments from every table in the system. The default size is usually
      suitable for most commitlog archiving, but if you want a finer
      granularity, 8 or 16 MB is reasonable.

      See also: <https://docs.datastax.com/en/cassandra/latest/cassandra/configuration/configLogArchive.html>
    default: 32
  concurrent_reads:
    description: |
      Workloads with more data than can fit in memory encounter a bottleneck
      in fetching data from disk during reads. Setting 'concurrent_reads' to
      (16 × number_of_drives) allows operations to queue low enough in the
      stack so that the OS and drives can reorder them. The default setting
      applies to both logical volume managed (LVM) and RAID drives.
    default: 16
  concurrent_writes:
    description: |
      Writes in Cassandra are rarely I/O bound, so the ideal number of
      concurrent writes depends on the number of CPU cores on the node. The
      recommended value is 8 × number_of_cpu_cores.
    default: 32
  file_cache_size_in_mb:
    description: |
      Total memory to use for SSTable-reading buffers.

      32MB of this are reserved for pooling buffers, the rest is used as a
      cache that holds uncompressed sstable chunks.

      When set to 'null' or not defined, this value defaults to the smaller of
      1/4 of heap (when heap is less than 2GB) or 512MB.
    default: null # min(1/4 heap, 512MB)
    example: 512
  memtable_flush_writers:
    description: |
      The number of memtable flush writer threads. These threads are blocked
      by disk I/O, and each one holds a memtable in memory while blocked. If
      your data directories are backed by SSDs, increase this setting to the
      number of cores.

      When set to 'null' or not defined, this value defaults to the smaller of
      number_of_disks or number_of_cores with a minimum of 2 and a maximum of
      8. Using this BOSH Release, Cassandra nodes always have one disk, so
      this calculation should always result in a value of '2'.
    default: null # min(8, max(2, min(number_of_disks, number_of_cores)))
    example: 2
  trickle_fsync:
    description: |
      When set to 'true', causes fsync to force the operating system to flush
      the dirty buffers at the set interval 'trickle_fsync_interval_in_kb'.
      Enable this parameter to prevent sudden dirty buffer flushing from
      impacting read latencies. Recommended for use with SSDs, but not with
      HDDs.
    default: false
  trickle_fsync_interval_in_kb:
    description: |
      The size of the fsync in kilobytes.
    default: 10240 # 10MB
  storage_port:
    description: |
      The port for inter-node communication.
    default: 7000
  ssl_storage_port:
    description: |
      The SSL port for encrypted communication. Unused when
      'internode_encryption_mode' is set to 'none'.
    default: 7001
  start_native_transport:
    description: |
      Enables or disables the native transport server. This server uses the
      same address as the 'rpc_address', but the port it uses is different
      from 'rpc_port'. See 'native_transport_port'.
    default: true
  native_transport_port:
    description: |
      The port where the CQL native transport listens for clients.
    default: 9042
  native_transport_max_threads:
    description: |
      The maximum number of thread handling requests. Similar to
      'rpc_max_threads', but this property differs as follows:

      - The default for 'native_transport_max_threads' is 128; the default for
        'rpc_max_threads' is 2048.

      - There is no corresponding 'native_transport_min_threads'.

      - Cassandra stops idle native transport threads after 30 seconds.
    default: 128
  native_transport_max_frame_size_in_mb:
    description: |
      The maximum allowed size of a frame. Frame (requests) larger than this
      are rejected as invalid.

      If you're changing this parameter, you may want to adjust
      'max_value_size_in_mb' accordingly. This should be positive and less
      than 2048.
    default: 256
  start_rpc:
    description: |
      Enables or disables the Thrift RPC server.
    default: true
  rpc_port:
    description: |
      Thrift port for client connections.
    default: 9160
  rpc_keepalive:
    description: |
      Enables or disables keepalive on client connections (RPC or native).
    default: true
  rpc_server_type:
    description: |
      Cassandra provides three options for the RPC server. 'sync' and 'hsha'
      performance is about the same, but 'hsha' uses less memory.

      - 'sync': (Default: one thread per Thrift connection.)
        For a very large number of clients, memory is the limiting factor. On
        a 64-bit JVM, 180KB is the minimum stack size per thread and
        corresponds to your use of virtual memory. Physical memory may be
        limited depending on use of stack space.

      - 'hsha':
        Half synchronous, half asynchronous. All Thrift clients are handled
        asynchronously using a small number of threads that does not vary with
        the number of clients. This mechanism scales well to many clients. The
        RPC requests are synchronous (one thread per active request).

        Note: If you select this option, you must change the default value
        (unlimited) of 'rpc_max_threads'.

      - Your own RPC server
        You must provide a fully-qualified class name of an
        'o.a.c.t.TServerFactory' that can create a server instance.
    default: sync
  rpc_min_threads:
    description: |
      The minimum thread pool size for remote procedure calls.
    default: 16
  rpc_max_threads:
    description: |
      Regardless of your choice of RPC server (See 'rpc_server_type'),
      'rpc_max_threads' dictates the maximum number of concurrent requests in
      the RPC thread pool. If you are using the parameter 'sync' (see
      'rpc_server_type') it also dictates the number of clients that can be
      connected. A high number of client connections could cause excessive
      memory usage for the thread stack. Connection pooling on the client side
      is highly recommended. Setting a 'rpc_max_threads' acts as a safeguard
      against misbehaving clients. If the number of threads reaches the
      maximum, Cassandra blocks additional connections until a client
      disconnects.
    default: 2048
  thrift_framed_transport_size_in_mb:
    description: |
      Frame size (maximum field length) for Thrift. The frame is the row or
      part of the row that the application is inserting.
    default: 15
  incremental_backups:
    description: |
      Backs up data updated since the last snapshot was taken. When enabled,
      Cassandra creates a hard link to each SSTable flushed or streamed
      locally in a backups subdirectory of the keyspace data. Removing these
      links is the operator's responsibility.

      See also: <https://docs.datastax.com/en/cassandra/latest/cassandra/operations/opsBackupIncremental.html>
    default: false
  snapshot_before_compaction:
    description: |
      Enables or disables taking a snapshot before each compaction. A snapshot
      is useful to back up data when there is a data format change. Be careful
      using this option: Cassandra does not clean up older snapshots
      automatically.
    default: false
  auto_snapshot:
    description: |
      Whether Cassandra takes a snapshot of the data before truncating a
      keyspace or dropping a table. To prevent data loss, DataStax strongly
      advises using the default setting. If you set 'auto_snapshot' to
      'false', data loss occurs on truncation or drop.
    default: true
  column_index_size_in_kb:
    description: |
      Granularity of the index of rows within a partition. For huge rows,
      decrease this setting to improve seek time. If you use key cache, be
      careful not to make this setting too large because key cache will be
      overwhelmed. If you're unsure of the size of the rows, it's best to use
      the default setting.
    default: 64
  concurrent_compactors:
    description: |
      The number of concurrent compaction processes allowed to run
      simultaneously on a node, not including validation compactions for anti-
      entropy repair. Simultaneous compactions help preserve read performance
      in a mixed read-write workload by limiting the number of small SSTables
      that accumulate during a single long-running compaction. If your data
      directories are backed by SSDs, increase this value to the number of
      cores. If compaction running too slowly or too fast, adjust
      'compaction_throughput_mb_per_sec' first.

      Note: Increasing concurrent compactors leads to more use of available
      disk space for compaction, because concurrent compactions happen in
      parallel, especially for STCS. Ensure that adequate disk space is
      available before increasing this configuration.

      If set to 'null' or not defined, this value defaults to the smaller of
      number_of_disks or number_of_cores, with a minimum of 2 and a maximum of
      8 per CPU core. Using this BOSH Release, Cassandra nodes always have one
      disk, so this calculation should always result in a value of '2'.
    default: null # min(8 × number_of_cores, max(2, min(number_of_disks, number_of_cores)))
    example: 8 # the number of CPU core, when using SSDs
  read_request_timeout_in_ms:
    description: |
      The number of milliseconds that the coordinator waits for read
      operations to complete before timing it out.
    default: 5000 # 5 seconds
  range_request_timeout_in_ms:
    description: |
      The number of milliseconds that the coordinator waits for sequential or
      index scans to complete before timing it out.
    default: 10000
  write_request_timeout_in_ms:
    description: |
      The number of milliseconds that the coordinator waits for a write
      operations to complete before timing it out for requests with at least
      one node in the local datacenter.
    default: 2000
  cas_contention_timeout_in_ms:
    description: |
      The number of milliseconds during which the coordinator continues to
      retry a CAS (compare and set) operation that contends with other
      proposals for the same row. If the coordinator cannot complete the
      operation within this timespan, it aborts the operation.
    default: 1000
  truncate_request_timeout_in_ms:
    description: |
      The number of milliseconds that the coordinator waits for a truncate
      (the removal of all data from a table) to complete before timing it out.
      The long default value allows Cassandra to take a snapshot before
      removing the data. If 'auto_snapshot' is disabled (not recommended), you
      can reduce this time.
    default: 60000
  request_timeout_in_ms:
    description: |
      The default timeout value for other miscellaneous operations.
    default: 10000
  cross_node_timeout:
    description: |
      Enables or disables operation timeout information exchange between nodes
      (to accurately measure request timeouts). If this property is disabled,
      the replica assumes any requests are forwarded to it instantly by the
      coordinator. During overload conditions this means extra time is
      required for processing already-timed-out requests.

        CAUTION:
        Before enabling this property make sure NTP (network time protocol) is
        installed and the times are synchronized among the nodes.
    default: false
  phi_convict_threshold:
    description: |
      Adjusts the sensitivity of the failure detector on an exponential scale.
      Generally this setting does not need adjusting.

      Use the default value for most situations, but increase it to 10 or 12
      for Amazon EC2 (due to frequently encountered network congestion). In
      unstable network environments (such as EC2 at times), raising the value
      to 10 or 12 helps prevent false failures. Values higher than 12 and
      lower than 5 are not recommended.

      See also: <https://docs.datastax.com/en/cassandra/latest/cassandra/architecture/archDataDistributeFailDetect.html>
    default: 8
  endpoint_snitch:
    description: |
      Set to a class that implements the IEndpointSnitch interface. Cassandra
      uses the snitch to locate nodes and route requests.

      - 'SimpleSnitch'
        Use for single-datacenter deployment or single-zone deployment in
        public clouds. Does not recognize datacenter or rack information.
        Treats strategy order as proximity, which can improve cache locality
        when you disable read repair.

      - 'GossipingPropertyFileSnitch'
        Recommended for production. Reads rack and datacenter for the local
        node in 'cassandra-rackdc.properties' file and propagates these values
        to other nodes via gossip. For migration from the PropertyFileSnitch,
        uses the 'cassandra-topology.properties' file if it is present.

      - 'PropertyFileSnitch'
        Determines proximity by rack and datacenter, which are explicitly
        configured in 'cassandra-topology.properties' file.

      - 'Ec2Snitch'
        For EC2 deployments in a single region. Loads region and availability
        zone information from the Amazon EC2 API. The region is treated as the
        datacenter and the availability zone as the rack and uses only private
        IP addresses. For this reason, it does not work across multiple
        regions.

      - 'Ec2MultiRegionSnitch'
        Uses the public IP as the broadcast_address to allow cross-region
        connectivity. This means you must also set seed addresses to the
        public IP and open the 'storage_port' or 'ssl_storage_port' on the
        public IP firewall. For intra-region traffic, Cassandra switches to
        the private IP after establishing a connection.

      - 'RackInferringSnitch'
        Proximity is determined by rack and datacenter, which are assumed to
        correspond to the 3rd and 2nd octet of each node's IP address,
        respectively. Best used as an example for writing a custom snitch
        class (unless this happens to match your deployment conventions).

      - 'GoogleCloudSnitch'
        Use for Cassandra deployments on Google Cloud Platform across one or
        more regions. The region is treated as a datacenter and the
        availability zones are treated as racks within the datacenter. All
        communication occurs over private IP addresses within the same logical
        network.

      - 'CloudstackSnitch'
        Use this snitch for Apache Cloudstack environments.
    default: PropertyFileSnitch
  bosh_to_cassandra_topology_mapping:
    description: |
      Maps BOSH Availability Zone (AZs) to Cassandra “DCs” (Data Centers) and
      “Racks”.

      To understand the notion of “Rack”, you need to know that the
      replication strategy implemented in Cassandra does its best not to have
      more than one replica on the same “Rack”, as informed by the snitch.
      (See also the 'endpoint_snitch' configuration property for more
      details.)

      To understand the notion of “DC”, you need to know that Cassandra
      implements different transfer strategies when nodes are not in the same
      Data Center and thus the latency is higher between them.

      Depending on your BOSH setup, a BOSH Availability Zone can be mapped to
      different zones (the usual setup) or different Data Centers (the more
      recent multi-CPI setup).

      The mapping you give here in this configuration property allows you to
      set a specific “DC” and “Rack” location to each BOSH availability zone.

      This mapping will be used to polulate the 'cassandra-topology.properties'
      (used by 'PropertyFileSnitch') and 'cassandra-rackdc.properties' (used
      by 'GossipingPropertyFileSnitch'). See the 'endpoint_snitch'
      configuration property for more details about snitch implementations.
    default: {}
    example:
      z1: { dc: DC1, rack: RAC1 }
      z2: { dc: DC1, rack: RAC2 }
      z3: { dc: DC2, rack: RAC1 }
      z4: { dc: DC2, rack: RAC2 }
      default: { dc: DC2, rack: RAC1 }
  dynamic_snitch_update_interval_in_ms:
    description: |
      The number of milliseconds between Cassandra's calculation of node
      scores. Because score calculation is CPU intensive, be careful when
      reducing this interval.
    default: 100 # 0.1 second
  dynamic_snitch_reset_interval_in_ms:
    description: |
      Time interval after which Cassandra resets all node scores. This allows
      a bad node to recover.
    default: 600000 # 10 minutes
  dynamic_snitch_badness_threshold:
    description: |
      The performance threshold for dynamically routing client requests away
      from a poorly performing node. Specifically, it controls how much worse
      a poorly performing node has to be before the dynamic snitch prefers
      other replicas over it. A value of 0.2 means Cassandra continues to
      prefer the static snitch values until the node response time is 20%
      worse than the best performing node. Until the threshold is reached,
      incoming requests are statically routed to the closest replica (as
      determined by the snitch). A value greater than zero for this parameter,
      with a value of less than 1.0 for 'read_repair_chance', maximizes cache
      capacity across the nodes.
    default: 0.1
  request_scheduler:
    description: |
      The scheduler to handle incoming client requests according to a defined
      policy. This scheduler is useful for throttling client requests in
      single clusters containing multiple keyspaces. This parameter is
      specifically for requests from the client and does not affect inter-node
      communication. Valid values:

      - 'org.apache.cassandra.scheduler.NoScheduler'
        Cassandra does no scheduling.

      - 'org.apache.cassandra.scheduler.RoundRobinScheduler'
        Cassandra uses a round robin of client requests to a node with a
        separate queue for each 'request_scheduler_id' property. (Currently
        'request_scheduler_id' can only be 'keyspace' as the scope of the
        scheduler's activity.)

      - Cassandra uses a Java class that implements the 'RequestScheduler'
        interface.
    default: org.apache.cassandra.scheduler.NoScheduler

  internode_encryption_mode:
    description: |
      Enables or disables encryption of inter-node communication using the
      'TLS_RSA_WITH_AES_128_CBC_SHA' cipher suite for authentication, key
      exchange, and encryption of data transfers. Use the DHE/ECDHE ciphers,
      such as 'TLS_DHE_RSA_WITH_AES_128_CBC_SHA' if running in (Federal
      Information Processing Standard) FIPS 140 compliant mode. Available
      inter-node options:

      - 'all': Encrypt all inter-node communications.
      - 'none': No encryption.
      - 'dc': Encrypt the traffic between the datacenters (server only).
      - 'rack': Encrypt the traffic between the racks (server only).

      See: <https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/configCassandra_yaml.html#configCassandra_yaml__ul_gbd_cns_1k>
    default: none
  client_encryption.enabled:
    default: false
    description: |
      Enables or disables client-to-node encryption.
  client_encryption.require_client_auth:
    default: false
    description: |
      Enables or disables client authentication via certificates.
  keystore_password:
    description: |
      Password for the keystore that is used to to store server and client
      encryption certificates and keys.
  cert:
    type: certificate
    description: |
      Cluster certificate, as can be provided by CredHub.
    example:
      ca: |
        -----BEGIN CERTIFICATE-----
        ...
        -----END CERTIFICATE-----
      certificate: |
        -----BEGIN CERTIFICATE-----
        ...
        -----END CERTIFICATE-----
      private_key: |
        -----BEGIN RSA PRIVATE KEY-----
        ...
        -----END RSA PRIVATE KEY-----
  trusted_ca_certs:
    description: |
      The overriding list of CA (Certificate Authority) certificates for the
      Cassandra node to trust.

      When this list is empty, a one-element list is built in order to at
      least trust the CA of the node certificate, as obtained with the
      'cert.ca' property. When this list is not empty, it MUST specify the CA
      of the node certificate.

      Having such a list is especially useful when:

      - Interacting with Cassandra nodes that are not part of the same
        deployment, not managed by the same BOSH server, or even not managed
        by BOSH at all. In this case any other CA certificate can be added
        here.

      - Rotating certificates, using a new certificate that is signed by a new
        Certificate Authority.

      The exact certificate rotation process consists in:

      1. Adding new CA certificate to this list, and re-deploy.

      2. Rotate server certificates, changing the 'cert' property and re-
         deploying. During this step, both old and new CA certificates are
         trusted.

      3. Remove old CA certificates from this list, and re-deploy.

      WARNING: this is just a list of plain (public) certificates, with no
      private keys. This is NOT a list of CredHub structures with the usual
      three properties (i.e. ".ca", ".certificate" and ".private_key").
    default: []
    example:
      - ((current_certificate.ca))
      - ((future_certificate.ca))
      - ((external_ca_cert)) # no private key, no structure.

  internode_compression:
    description: |
      Controls whether traffic between nodes is compressed. Valid values:

      - 'all'
        Compresses all traffic.

      - 'dc'
        Compresses traffic between datacenters only.

      - 'none'
        No compression.
    default: dc
  inter_dc_tcp_nodelay:
    description: |
      Enable this property or 'disable tcp_nodelay' for inter-datacenter
      communication. If this property is disabled, the network sends larger,
      but fewer, network packets. This reduces overhead from the TCP protocol
      itself. However, disabling 'inter_dc_tcp_nodelay' may increase latency
      by blocking cross data-center responses.
    default: false

  tombstone_warn_threshold:
    description: |
      Cassandra issues a warning if a query scans more than this number of
      tombstones.
    default: 1000
  tombstone_failure_threshold:
    description: |
      Cassandra aborts a query if it scans more than this number of
      tombstones.
    default: 100000
  max_value_size_in_mb:
    description: |
      The maximum size of any value in SSTables.

      Any value size larger than this threshold will result into marking an
      SSTable as corrupted.

      This should be positive and less than 2048.
    default: 256

  max_heap_size:
    description: |
      The total amount of memory dedicated to the Java heap.

      When both 'max_heap_size' and 'heap_newsize' are set to an empty string
      value (""), then the default max heap size is based on the following
      calculation:

        max(min(1/2 ram, 1GB), min(1/4 ram, 8GB))

      Which can be described by this algorithm:
        1. calculate 1/2 ram and cap to 1024MB
        2. calculate 1/4 ram and cap to 8192MB
        3. pick the max
    default: "" # max(min(1/2 ram, 1GB), min(1/4 ram, 8GB))
    example: 8G
  heap_newsize:
    description: |
      Size of the young generation.

      When both 'max_heap_size' and 'heap_newsize' are set to an empty string
      value (""), then the default young generation size is computed as
      folows:

        min(max_sensible_per_modern_cpu_core * num_cores, 1/4 * heap size)

      Where 'max_sensible_per_modern_cpu_core' is 100 MB, which assumes a
      modern 8-core+ machine for decent pause times. If in doubt, and if you
      do not particularly want to tweak, go with 100 MB per physical CPU core.

      On Linux, the 'num_cores' value is taken from the 'processor:' property
      as found in '/proc/cpuinfo'. Be careful that in BOSH-Lite (using Garden
      RunC), this may not be accurate.

      The main trade-off for the young generation is that the larger it is,
      the longer GC pause times will be. The shorter it is, the more expensive
      GC will be (usually).
    default: "" # min(max_sensible_per_modern_cpu_core * num_cores, 1/4 * heap size)
    example: 1G
  cassandra_password:
    description: |
      This is the password for the default 'cassandra' admin user.

      By default, the Cassandra daemon uses 'cassandra' as the password for
      this user and this value is hardcoded in Cassandra code, so we
      shamelessly use this as the default here.

      For security reasons, you are highly recommended to use a strong
      password here for production systems.
    default: cassandra
  validate_ssl_TF:
    description: |
      When validate is enabled, the locally installed cqlsh clients will
      verify that the certificate is trusted, and the host in the certificate
      will be compared to the host of the machine to which the clients are
      connected.
    default: false

  system_auth_keyspace_replication_factor:
    description: |
      The replication factor to apply to the 'system_auth' keyspace that holds
      users and passwords.

      When this value is nor defined or 'null', the default replication factor
      used is the number of seeds instances, as can be inferred when
      traversing the 'seeds' Bosh Link.
    default: null
    example: 3

  disable_linux_swap:
    description: |
      Suppress Linux swap on pre-start, in order to ensure good
      performances for Cassandra.

      This is a workaround for IaaS where the property
      'env.bosh.swap_size' set to 0 does not properly suppress Linux
      swap.

      In Bosh-Lite, you need to set this to 'false', as the 'swapoff'
      command cannot be invoked within Garden containers.
    default: true

  jmx_exporter_enabled:
    description: |
      Scrape and expose mBeans of a JMX target.
    default: true
  jmx_exporter_port:
    description: |
      Port on which to expose metrics and web interface.
    default: 9001
